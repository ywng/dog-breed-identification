{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 120\n",
    "batch_size = 5\n",
    "epochs = 15\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize])\n",
    "valid_transform = transforms.Compose([transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                normalize])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(\"./data/train/\", train_transform);\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "validset = torchvision.datasets.ImageFolder(\"./data/valid/\", valid_transform);\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "classes = trainloader.dataset.classes\n",
    "pickle.dump(classes, open(\"dog_breeds_labels.pickle\", \"wb\"), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, train, valid, optimizer, criterion, epochs=1):\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch ', epoch + 1, '/', epochs)\n",
    "        \n",
    "        running_loss = 0.\n",
    "        running_corrects = 0.\n",
    "        running_batches = 0.\n",
    "       \n",
    "        model.train()\n",
    "        for i, (input, target) in enumerate(train):\n",
    "            input_var = torch.autograd.Variable(input)\n",
    "            target_var = torch.autograd.Variable(target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(input_var)\n",
    "            if type(output) == tuple:\n",
    "                output, _ = output\n",
    "            _, preds = torch.max(output.data, 1)\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.data[0]\n",
    "            running_corrects += torch.sum(preds == target)\n",
    "            running_batches += 1.\n",
    "            \n",
    "            ''' for testing \n",
    "            if i > 10:\n",
    "                break\n",
    "            '''\n",
    "\n",
    "            print('\\r', 'Batch', i, 'Loss', loss.data[0], end='')\n",
    "            \n",
    "        train_loss = running_loss / running_batches\n",
    "        train_acc = running_corrects / len(train.dataset)\n",
    "        print('\\r', \"Train Loss\", train_loss, \"Train Accuracy\", train_acc)\n",
    "            \n",
    "        running_loss = 0.\n",
    "        running_corrects = 0.\n",
    "        running_batches = 0.\n",
    "\n",
    "        model.eval()\n",
    "        for i, (input, target) in enumerate(valid):\n",
    "            input_var = torch.autograd.Variable(input, volatile=True)\n",
    "            target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "            output = model(input_var)\n",
    "            if type(output) == tuple:\n",
    "                output, _ = output\n",
    "            _, preds = torch.max(output.data, 1)\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "            running_loss += loss.data[0]\n",
    "            running_corrects += torch.sum(preds == target)\n",
    "            running_batches += 1.\n",
    "            \n",
    "            ''' for testing \n",
    "            if i > 10:\n",
    "                break\n",
    "            '''\n",
    "\n",
    "        valid_loss = running_loss / running_batches\n",
    "        valid_acc = running_corrects / len(valid.dataset)\n",
    "        print('\\r', \"Val Loss\", valid_loss, \"Val Accuracy\", valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 / 15\n",
      " Train Loss 3.729998452177888 Train Accuracy 0.20447634107772777\n",
      " Val Loss 2.8896977499088488 Val Accuracy 0.3448275862068966\n",
      "Epoch  2 / 15\n",
      " Train Loss 2.9237218398634788 Train Accuracy 0.33146819121761345\n",
      " Val Loss 2.541808501864317 Val Accuracy 0.4032983508245877\n",
      "Epoch  3 / 15\n",
      " Train Loss 2.6295154970488865 Train Accuracy 0.37842111665247535\n",
      " Val Loss 2.586290212803894 Val Accuracy 0.4352823588205897\n",
      "Epoch  4 / 15\n",
      " Train Loss 2.5055620380629158 Train Accuracy 0.4077362851234643\n",
      " Val Loss 2.2854568257825125 Val Accuracy 0.4547726136931534\n",
      "Epoch  5 / 15\n",
      " Train Loss 2.410577801014877 Train Accuracy 0.42598224060333295\n",
      " Val Loss 2.1819819955735444 Val Accuracy 0.4817591204397801\n",
      "Epoch  6 / 15\n",
      " Train Loss 2.3097222640838666 Train Accuracy 0.4428901593480112\n",
      " Val Loss 2.1896566720635855 Val Accuracy 0.48125937031484256\n",
      "Epoch  7 / 15\n",
      " Train Loss 2.2193444372423694 Train Accuracy 0.46417710740785795\n",
      " Val Loss 2.291605162139032 Val Accuracy 0.4867566216891554\n",
      "Epoch  8 / 15\n",
      " Train Loss 2.222319803657265 Train Accuracy 0.46320398978226496\n",
      " Val Loss 2.135300119907103 Val Accuracy 0.5082458770614693\n",
      "Epoch  9 / 15\n",
      " Train Loss 2.153236253204045 Train Accuracy 0.47938207030774843\n",
      " Val Loss 2.0283896699788 Val Accuracy 0.5152423788105946\n",
      "Epoch  10 / 15\n",
      " Train Loss 2.14419416815586 Train Accuracy 0.4821797834813283\n",
      " Val Loss 2.078527294382821 Val Accuracy 0.5177411294352824\n",
      "Epoch  11 / 15\n",
      " Train Loss 2.0709623054168143 Train Accuracy 0.4951952317236346\n",
      " Val Loss 2.0832500324783845 Val Accuracy 0.512743628185907\n",
      "Epoch  12 / 15\n",
      " Train Loss 2.0511688732857727 Train Accuracy 0.4981145846004136\n",
      " Val Loss 2.0904410101451267 Val Accuracy 0.5182408795602199\n",
      "Epoch  13 / 15\n",
      " Train Loss 2.0633742052872064 Train Accuracy 0.49860114341321005\n",
      " Val Loss 2.042223289163035 Val Accuracy 0.5272363818090955\n",
      "Epoch  14 / 15\n",
      " Train Loss 1.9967539321166947 Train Accuracy 0.5164821797834813\n",
      " Val Loss 2.001895168369123 Val Accuracy 0.5157421289355323\n",
      "Epoch  15 / 15\n",
      " Train Loss 2.0143951580539845 Train Accuracy 0.5104001946235251\n",
      " Val Loss 2.0712814674476077 Val Accuracy 0.5132433783108445\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.squeezenet1_1(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Conv2d(512, num_classes, kernel_size=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.AvgPool2d(13)\n",
    ")\n",
    "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), num_classes)\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#Optimize only the classifier\n",
    "optimizer = torch.optim.SGD(list(filter(lambda p: p.requires_grad, model.parameters())), lr=0.001, momentum=0.9)\n",
    "\n",
    "train(model, trainloader, validloader, optimizer, criterion, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'dog-breed-ident-squeezenet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DogsData(Dataset):\n",
    "    def __init__(self, root_dir, labels, transform, output_class=True):\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.output_class = output_class\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.labels.iloc[idx]\n",
    "        path = '{}/{}.jpg'.format(self.root_dir, item['id'])\n",
    "        image = Image.open(path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if not self.output_class:\n",
    "            return image\n",
    "        \n",
    "        return image, item['class']\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    DogsData('./data/test/x', sample_submission, valid_transform, output_class=False),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch 2071"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('dog-breed-ident-squeezenet.pt'))\n",
    "model.eval()\n",
    "results = []\n",
    "\n",
    "for i, input in enumerate(test_loader):\n",
    "    input_var = torch.autograd.Variable(input, volatile=True)\n",
    "    output = model(input_var)\n",
    "    results.append(F.softmax(output, dim=1).cpu().data.numpy())\n",
    "    print('\\r', 'Batch', i, end='')\n",
    "    \n",
    "    ''' for testing \n",
    "    if i > 10:\n",
    "        break\n",
    "    '''\n",
    "        \n",
    "results = np.concatenate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10357, 120)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = sample_submission['id'].values\n",
    "sample_df = pd.DataFrame(ids, columns=['id'])\n",
    "#sample_df = sample_df[:48] #for testing only\n",
    "#sample_df.shape\n",
    "for index, breed in enumerate(classes):\n",
    "    sample_df[breed] = results[:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_df.to_csv('pred_squeezenet.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
