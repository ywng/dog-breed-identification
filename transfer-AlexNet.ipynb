{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 120\n",
    "batch_size = 5\n",
    "epochs = 15\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize])\n",
    "valid_transform = transforms.Compose([transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                normalize])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(\"./data/train/\", train_transform);\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "validset = torchvision.datasets.ImageFolder(\"./data/valid/\", valid_transform);\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "classes = trainloader.dataset.classes\n",
    "pickle.dump(classes, open(\"dog_breeds_labels.pickle\", \"wb\"), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, train, valid, optimizer, criterion, epochs=1):\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch ', epoch + 1, '/', epochs)\n",
    "        \n",
    "        running_loss = 0.\n",
    "        running_corrects = 0.\n",
    "        running_batches = 0.\n",
    "       \n",
    "        model.train()\n",
    "        for i, (input, target) in enumerate(train):\n",
    "            input_var = torch.autograd.Variable(input)\n",
    "            target_var = torch.autograd.Variable(target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(input_var)\n",
    "            _, preds = torch.max(output.data, 1)\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.data[0]\n",
    "            running_corrects += torch.sum(preds == target)\n",
    "            running_batches += 1.\n",
    "            \n",
    "            ''' for testing \n",
    "            if i > 10:\n",
    "                break\n",
    "            '''\n",
    "\n",
    "            print('\\r', 'Batch', i, 'Loss', loss.data[0], end='')\n",
    "            \n",
    "        train_loss = running_loss / running_batches\n",
    "        train_acc = running_corrects / len(train.dataset)\n",
    "        print('\\r', \"Train Loss\", train_loss, \"Train Accuracy\", train_acc)\n",
    "            \n",
    "        running_loss = 0.\n",
    "        running_corrects = 0.\n",
    "        running_batches = 0.\n",
    "\n",
    "        model.eval()\n",
    "        for i, (input, target) in enumerate(valid):\n",
    "            input_var = torch.autograd.Variable(input, volatile=True)\n",
    "            target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "            output = model(input_var)\n",
    "            _, preds = torch.max(output.data, 1)\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "            running_loss += loss.data[0]\n",
    "            running_corrects += torch.sum(preds == target)\n",
    "            running_batches += 1.\n",
    "            \n",
    "            ''' for testing \n",
    "            if i > 10:\n",
    "                break\n",
    "            '''\n",
    "\n",
    "        valid_loss = running_loss / running_batches\n",
    "        valid_acc = running_corrects / len(valid.dataset)\n",
    "        print('\\r', \"Val Loss\", valid_loss, \"Val Accuracy\", valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 / 15\n",
      " Train Loss 3.0162620454392535 Train Accuracy 0.286948059846734\n",
      " Val Loss 2.0276138120728016 Val Accuracy 0.456271864067966\n",
      "Epoch  2 / 15\n",
      " Train Loss 2.4084897257002655 Train Accuracy 0.3904634472691887\n",
      " Val Loss 1.9403785601458738 Val Accuracy 0.4752623688155922\n",
      "Epoch  3 / 15\n",
      " Train Loss 2.2282566048884282 Train Accuracy 0.4353484977496655\n",
      " Val Loss 1.9679940441684876 Val Accuracy 0.4877561219390305\n",
      "Epoch  4 / 15\n",
      " Train Loss 2.1597433317577224 Train Accuracy 0.4465393504439849\n",
      " Val Loss 1.9807465990489705 Val Accuracy 0.4702648675662169\n",
      "Epoch  5 / 15\n",
      " Train Loss 2.079471355142202 Train Accuracy 0.46733973969103515\n",
      " Val Loss 2.0347287806942407 Val Accuracy 0.45077461269365315\n",
      "Epoch  6 / 15\n",
      " Train Loss 2.0823272359905634 Train Accuracy 0.4634472691886632\n",
      " Val Loss 2.08511346311975 Val Accuracy 0.4577711144427786\n",
      "Epoch  7 / 15\n",
      " Train Loss 2.0326897098391252 Train Accuracy 0.47621943802457123\n",
      " Val Loss 1.965133282407059 Val Accuracy 0.49375312343828087\n",
      "Epoch  8 / 15\n",
      " Train Loss 2.0101539833046562 Train Accuracy 0.48290962170052304\n",
      " Val Loss 2.089448807689656 Val Accuracy 0.44677661169415295\n",
      "Epoch  9 / 15\n",
      " Train Loss 2.004491050464404 Train Accuracy 0.4796253497141467\n",
      " Val Loss 2.1646147765982153 Val Accuracy 0.46476761619190404\n",
      "Epoch  10 / 15\n",
      " Train Loss 2.0107072629906395 Train Accuracy 0.48765357012528887\n",
      " Val Loss 2.130597436860984 Val Accuracy 0.46676661669165415\n",
      "Epoch  11 / 15\n",
      " Train Loss 1.9907973265773575 Train Accuracy 0.4904512832988687\n",
      " Val Loss 2.2351735050777237 Val Accuracy 0.4427786106946527\n",
      "Epoch  12 / 15\n",
      " Train Loss 2.0481532454241553 Train Accuracy 0.4767059968373677\n",
      " Val Loss 2.204008758279432 Val Accuracy 0.4567716141929036\n",
      "Epoch  13 / 15\n",
      " Train Loss 2.001731245355584 Train Accuracy 0.4855856951709038\n",
      " Val Loss 2.159881801857727 Val Accuracy 0.4577711144427786\n",
      "Epoch  14 / 15\n",
      " Train Loss 2.0538804710839837 Train Accuracy 0.4805984673397397\n",
      " Val Loss 2.2062114010288605 Val Accuracy 0.4512743628185907\n",
      "Epoch  15 / 15\n",
      " Train Loss 2.0739597195142307 Train Accuracy 0.48230142318452746\n",
      " Val Loss 2.3191918419381405 Val Accuracy 0.4292853573213393\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "num_features = model.classifier[6].in_features\n",
    "features = list(model.classifier.children())[:-1]\n",
    "features.extend([nn.Linear(num_features, num_classes)])\n",
    "#replace the classifier of the trained network with our dog classifier\n",
    "#parameters of newly constructed modules have required_grad=True by default\n",
    "#model.fc = nn.Linear(num_features, num_classes) \n",
    "\n",
    "model.classifier = nn.Sequential(*features)\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#Optimize only the classifier\n",
    "optimizer = torch.optim.SGD(list(filter(lambda p: p.requires_grad, model.parameters())), lr=0.001, momentum=0.9)\n",
    "\n",
    "train(model, trainloader, validloader, optimizer, criterion, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'dog-breed-ident-AlexNet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DogsData(Dataset):\n",
    "    def __init__(self, root_dir, labels, transform, output_class=True):\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.output_class = output_class\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.labels.iloc[idx]\n",
    "        path = '{}/{}.jpg'.format(self.root_dir, item['id'])\n",
    "        image = Image.open(path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if not self.output_class:\n",
    "            return image\n",
    "        \n",
    "        return image, item['class']\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    DogsData('./data/test/x', sample_submission, valid_transform, output_class=False),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch 2071"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('dog-breed-ident-AlexNet.pt'))\n",
    "model.eval()\n",
    "results = []\n",
    "\n",
    "for i, input in enumerate(test_loader):\n",
    "    input_var = torch.autograd.Variable(input, volatile=True)\n",
    "    output = model(input_var)\n",
    "    results.append(F.softmax(output, dim=1).cpu().data.numpy())\n",
    "    print('\\r', 'Batch', i, end='')\n",
    "    \n",
    "    ''' for testing \n",
    "    if i > 10:\n",
    "        break\n",
    "    '''\n",
    "        \n",
    "results = np.concatenate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10357, 120)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = sample_submission['id'].values\n",
    "sample_df = pd.DataFrame(ids, columns=['id'])\n",
    "#sample_df = sample_df[:48] #for testing only\n",
    "#sample_df.shape\n",
    "for index, breed in enumerate(classes):\n",
    "    sample_df[breed] = results[:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_df.to_csv('pred_AlexNet.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
